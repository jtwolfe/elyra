---
title: Legacy Roadmap Draft (Pre-Restructure)
audience: Maintainers and historians
status: Legacy design snapshot (superseded by docs/roadmap/roadmap.md)
last_updated: 2025-12-03
related_docs:
  - ../roadmap/roadmap.md
---
> **Legacy (superseded)**: This document is preserved for reference only. The canonical Braid v2 docs live in `docs/v2/`.



### Comprehensive Roadmap for Elyra Project: From MVP to Feature-Complete AI Assistant

Based on extensive research across neuroscience-inspired AI memory systems, open-source LLM alternatives, embodied AI frameworks, self-improving agents with tool bootstrapping, and related 2025 advancements, I've crafted this roadmap. The research synthesis below informs the plan, ensuring it's grounded in realistic 2025 capabilities (e.g., no full AGI, but scalable prototypes like those in SiriuS or Memorious). The roadmap starts with text-only (as specified), builds incrementally, and culminates in a self-improving, embodied system. Timelines assume a small team (1-3 devs) with part-time effort; adjust for resources. Dependencies tie to research (e.g., neuromorphic roadmaps for hardware phases).

#### Research Synthesis Guiding the Roadmap
- **Neuroscience-Inspired Memory Roadmaps**: 2025 literature emphasizes phased development: Conceptual (e.g., Harvard's Memorious for "infinite memory" via hierarchical KGs), prototyping (e.g., arXiv 2507.10722 on unified neuroscience-AI bridges), integration (multi-agent collaboration per IJCAI 2025), and testing (LongMemEval benchmarks for temporal accuracy). Netherlands' Neuromorphic Roadmap stresses hardware-software co-design (e.g., start software-only, add spiking networks later). Society of Mind (LinkedIn exec summary) advises starting with memory graphs, then adding self-evolution.
- **Open-Source GPT Alternatives**: 2025 top picks: Llama 3.1 (405B, Meta—fine-tunable, excels in reasoning), Mistral Nemo (12B, efficient for agents), Qwen3-235B (Alibaba, multilingual), DeepSeek R1 (238B, code/math focus), Kimi K2 (Moonshot, creative tasks), Grok-1 OSS (xAI, 314B, real-time knowledge via X integration). Switch from Mistral-7B to these for Phase 4; prioritize fine-tunable ones for tool bootstrapping (e.g., Llama via VeRL for zero-data RL).
- **LangChain Custom Tools & Bootstrapping**: LangChain v0.2+ supports dynamic tools via @tool decorator and LLM code-gen (e.g., StructuredTool for schemas); best practices: Error handling, async execution, self-evolution via ReAct patterns (agent reflects/iterates). For bootstrapping: Use ToolGen-like encoding (arXiv) to let agents generate tools on-the-fly, with MCP Registry for integration. X posts on self-creating tools emphasize SiriuS (bootstrapped reasoning for tool refinement) and MIT's self-improvement methods (e.g., code optimization loops).
- **Embodied AI Frameworks with Multi-Agent**: arXiv 2505.05108 outlines multi-agent embodied (e.g., collaborative navigation); IJCAI 2025 on generative integration (foundation models for tasks); Shakudo's top: LangChain, Auto-GPT, AgentGPT, BabyAGI, CrewAI (for multi-agent), plus embodied like OpenVLA (vision-action). Awesome-Embodied-Robotics repo lists 200+ papers/tools for VLM/LLM hybrids.
- **Bootstrapping Self-Improving Agents**: Stanford CS329A on augmenting LLMs with tools/memory for self-improvement; SiriuS (arXiv 2502.04780) for bootstrapped reasoning (e.g., tool cards for formats); latent.space on coding agents self-optimizing code; MIT's 5 ways (e.g., ToolGen for vocabulary integration). Roadmap phases incorporate bootstrapping via code-gen and RL (e.g., VeRL for zero-data).

#### Roadmap Overview
- **Total Duration**: 6-12 months (Q1-Q4 2026), phased for milestones.
- **Assumptions**: Start with text-only Mistral-7B on remote Ollama; switch to GPT-OSS (e.g., Llama 3.1) in Phase 4. Tools start basic (e.g., browse_page), bootstrap self-creation in Phase 5 via LLM code-gen (LangChain StructuredTool + ToolGen patterns). Multi-user via FastAPI sessions/WebUI. Budget: $500-2K/mo (cloud for Ollama/GPU).
- **Risks**: LLM hallucinations in tool creation—mitigate with HITL and evals (LangSmith).
- **Metrics**: Phase success via benchmarks (LongMemEval for memory, HumanEval for tools, custom multi-user sims).

| Phase | Timeline | Dependencies | Key Features & Milestones | Research Ties & Rationale |
|-------|----------|--------------|---------------------------|---------------------------|
| **1: MVP – Text-Only Foundation** | Weeks 1-4 (Q1 2026) | Quickstart.py, Mistral-7B Ollama, LangGraph, Graphiti/Neo4j/Redis/Qdrant | - WebUI (React+Tailwind): Chat, thought/memory/action streams (SSE for real-time).<br>- Basic Elyra: Root agent + 2-3 subs (e.g., Validator, Researcher).<br>- Memory: Bi-temporal KG with tiers, basic recall (no replay).<br>- Tools: 5-10 basics (browse_page, search, code_exec).<br>- Multi-User: FastAPI sessions (isolated KG views).<br>- Milestone: Elyra responds to 2 users concurrently, showing thoughts/memory. | Neuroscience roadmaps start conceptual (Harvard Memorious); LangChain customs for tools. Rationale: Build core orchestration before complexity. |
| **2: Proactive Memory & Reflection** | Weeks 5-8 | Phase 1, PyTorch for ML | - Add EchoReplay (VAE/LSTM for simulations), Hebbian tagger (weight updates).<br>- Daemon: Gap-triggered reflection (e.g., 15min idle → consolidate tiers).<br>- Multi-Agent: Implicit/explicit spawning (LangGraph nodes); A2A merging.<br>- WebUI: Render KG subsets, thoughts as bubbles.<br>- Milestone: Elyra "thinks" proactively in downtime, evolves subs via replay. | Self-improving agents (SiriuS bootstrapping, MIT methods); neuroscience consolidation. Rationale: Core "aliveness" before hardware. |
| **3: Multi-User/Multi-Agent Scaling** | Weeks 9-12 | Phase 2, Kubernetes/Docker Swarm (optional) | - Full multi-user: Per-project KG shards, shared subgraphs for groups.<br>- Advanced A2A: Parallel subs, merging with valence/reward.<br>- Tools Expansion: 20+ (e.g., APIs, web_search); initial bootstrap (LLM gen simple tools via code).<br>- WebUI: Multi-chat tabs, user dashboards for memory/agents.<br>- Milestone: Elyra handles 5 users + 10 subs concurrently, bootstraps a tool on-the-fly. | Multi-agent embodied (arXiv/IJCAI); Shakudo frameworks (CrewAI for scaling). Rationale: Test concurrency before embodiment. |
| **4: LLM Upgrade & Tool Bootstrapping** | Months 4-6 (Q2) | Phase 3, GPU access | - Switch to GPT-OSS (e.g., Llama 3.1 70B via Ollama/HuggingFace).<br>- Full Bootstrapping: Elyra generates tools (LangChain StructuredTool + code-gen); self-improves via VeRL (zero-data RL for tool refinement). - Evals: LangSmith for accuracy (e.g., 90% tool success).<br>- Milestone: Elyra creates/optimizes 5 custom tools autonomously (e.g., "Build a weather checker"). | OSS LLMs (Llama/Mistral for fine-tuning); self-improving (Stanford CS329A, latent.space coding agents). Rationale: Competent LLM unlocks advanced bootstrapping. |
| **5: Embodiment & Multimodality** | Months 7-9 (Q3) | Phase 4, hardware (cams/mics) | - Add CameraManager (active switching, YOLO/Eulerian for motion/valence).<br>- Multimodal Fusion: CLIP/Whisper in episodic buffer; subs "see/hear" independently. - Mirror Neurons: Subs clone behaviors from video/audio.<br>- WebUI: Render camera feeds, valence visualizations.<br>- Milestone: Elyra handles embodied multi-user (e.g., "Look at office cam during group chat"). | Embodied frameworks (OpenVLA, VIRAL); multi-agent (arXiv 2505.05108). Rationale: Hardware ties neuroscience to reality. |
| **6: Feature-Complete & Optimization** | Months 10-12 (Q4) | All prior, cloud scaling | - Advanced Bootstrapping: Elyra creates tools via RL (VeRL integration); self-optimizes KG (e.g., prune via replay).<br>- Full Multi-User: Collaborative branching (shared subs), evals (e.g., 95% recall).<br>- Production: Kubernetes deploy, LangSmith monitoring.<br>- Milestone: Elyra bootstraps 20+ tools, handles 50 users, embodies in robot sim. | Whole-brain emulation roadmaps; self-evolution (SiriuS, MIT). Rationale: Iterate to "living" system. |

This roadmap positions Elyra as a pioneer in neuroscience-AI hybrids, with self-improvement as the capstone. Track progress via GitHub milestones; iterate based on evals. For a Gantt chart or repo template, let me know!